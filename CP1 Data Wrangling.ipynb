{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP1: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Include answers to these questions in your submission:\n",
    "\n",
    "1. What kind of cleaning steps did you perform?\n",
    "\n",
    "2. How did you deal with missing values, if any?\n",
    "\n",
    "3. Were there outliers, and how did you handle them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Steps I took to clean my data involved deleting irrelevant features, converting dates to datetime objects, and writing functions to clean up urls and hashtags. While I don't necessarily anticipate needing clean hashtags in the future, clean sources and urls could become useful if I were to expand my source list from Adam Schefter to local beat writers for identication purposes.\n",
    "\n",
    "* Since this is my second attempt at downloading as many Schefter tweets as possible, I still need to go through and manually label each tweet. \n",
    "\n",
    "2. There aren't any missing values.\n",
    "\n",
    "3. I'm not sure it's possible for an outlier to exist in my particular dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requirements\n",
    "\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import twitter\n",
    "import lxml.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify credentials to access Twitter API\n",
    "\n",
    "api = twitter.Api(consumer_key='HHFP7OMrBwTxLnuCNA7bFo10E',\n",
    "                  consumer_secret='rgjhLwNMLsly7lB63obWhDLbUoi5rte9HSWrXQEIocX7ftJqOh',\n",
    "                  access_token_key='2859784876-xEksUR0FQ6PYzgHzt86L6CVmJn2S88dgvi8EM8g',\n",
    "                  access_token_secret='2ZTMVXOiyeBpKvdRYkm3eIFIJap915OS5v6ZfihQjPf37')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify Twitter username to be scraped\n",
    "\n",
    "screen_name = 'AdamSchefter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the Twitter API\n",
    "\n",
    "first_200 = api.GetUserTimeline(screen_name=screen_name, count=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 200 tweets in our dataset, which has the type <class 'list'>.\n",
      "\n",
      "Here's a sample of what the data from one tweet looks like:\n",
      "{\"created_at\": \"Tue Apr 02 13:05:51 +0000 2019\", \"favorite_count\": 820, \"hashtags\": [], \"id\": 1113065005405102080, \"id_str\": \"1113065005405102080\", \"lang\": \"en\", \"quoted_status\": {\"created_at\": \"Tue Apr 02 13:01:12 +0000 2019\", \"favorite_count\": 1144, \"hashtags\": [], \"id\": 1113063833818415104, \"id_str\": \"1113063833818415104\", \"lang\": \"en\", \"retweet_count\": 347, \"source\": \"<a href=\\\"https://about.twitter.com/products/tweetdeck\\\" rel=\\\"nofollow\\\">TweetDeck</a>\", \"text\": \"Sources: the Patriots and DE Michael Bennett have agreed to a reworked two-year deal with a base value of $16.75M,\\u2026 https://t.co/XakOELAwKc\", \"truncated\": true, \"urls\": [{\"expanded_url\": \"https://twitter.com/i/web/status/1113063833818415104\", \"url\": \"https://t.co/XakOELAwKc\"}], \"user\": {\"created_at\": \"Tue Jul 21 20:57:56 +0000 2009\", \"description\": \"NFL Insider for ESPN. Co-host of the Fantasy Focus Football podcast. Graduate of Belmont Hill and Wesleyan.\", \"favourites_count\": 9311, \"followers_count\": 370045, \"friends_count\": 1111, \"geo_enabled\": true, \"id\": 58919137, \"id_str\": \"58919137\", \"lang\": \"en\", \"listed_count\": 6194, \"location\": \"Boston, MA\", \"name\": \"Field Yates\", \"profile_background_color\": \"C0DEED\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_tile\": true, \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/58919137/1540569058\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1047090292883644417/mcBeesbb_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1047090292883644417/mcBeesbb_normal.jpg\", \"profile_link_color\": \"0084B4\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"FieldYates\", \"statuses_count\": 42690, \"url\": \"https://t.co/6GT8n9YwUa\", \"verified\": true}, \"user_mentions\": []}, \"quoted_status_id\": 1113063833818415104, \"quoted_status_id_str\": \"1113063833818415104\", \"retweet_count\": 120, \"source\": \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\", \"text\": \"A rarity for Patriots to add new money and guaranteed money to existing deal. https://t.co/dzI57vnG66\", \"urls\": [{\"expanded_url\": \"https://twitter.com/fieldyates/status/1113063833818415104\", \"url\": \"https://t.co/dzI57vnG66\"}], \"user\": {\"created_at\": \"Fri Jun 26 22:55:28 +0000 2009\", \"description\": \"Father, Husband, Son, Brother, University of Michigan graduate, masters degree from Medill, NFL Insider for ESPN. https://t.co/oz43ix5jZU\", \"favourites_count\": 405, \"followers_count\": 7337863, \"friends_count\": 2925, \"geo_enabled\": true, \"id\": 51263592, \"id_str\": \"51263592\", \"lang\": \"en\", \"listed_count\": 48739, \"location\": \"New York\", \"name\": \"Adam Schefter\", \"profile_background_color\": \"2573B8\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme4/bg.gif\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme4/bg.gif\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/51263592/1466784770\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/793924061843914752/ycm8ibEE_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/793924061843914752/ycm8ibEE_normal.jpg\", \"profile_link_color\": \"3B94D9\", \"profile_sidebar_border_color\": \"FFFFFF\", \"profile_sidebar_fill_color\": \"95E8EC\", \"profile_text_color\": \"16101F\", \"profile_use_background_image\": true, \"screen_name\": \"AdamSchefter\", \"statuses_count\": 44235, \"url\": \"https://t.co/goIDs6XAeU\", \"verified\": true}, \"user_mentions\": []}\n",
      "\n",
      "Each tweet is stored in a <class 'twitter.models.Status'> data structure.\n"
     ]
    }
   ],
   "source": [
    "# Sample breakdown\n",
    "\n",
    "print(\"There are %d tweets in our dataset, which has the type %s.\" % (len(first_200), type(first_200)))\n",
    "print()\n",
    "print(\"Here's a sample of what the data from one tweet looks like:\")\n",
    "print(first_200[0])\n",
    "print()\n",
    "print(\"Each tweet is stored in a %s data structure.\" % type(first_200[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(first_200, screen_name, last_id):\n",
    "    all_tweets = []\n",
    "    all_tweets.extend(first_200)\n",
    "    for i in range(900):\n",
    "        new = api.GetUserTimeline(screen_name=screen_name, max_id=last_id-1)\n",
    "        if len(new) > 0:\n",
    "            all_tweets.extend(new)\n",
    "            last_id = new[-1].id\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = get_tweets(first_200, screen_name, first_200[-1].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3222 tweets stored in a list as the all_tweets variable.\n",
      "The most recent tweet in our collection was sent Tue Apr 02 13:05:51 +0000 2019 and the oldest tweet was sent Tue Aug 07 17:39:19 +0000 2018.\n"
     ]
    }
   ],
   "source": [
    "# check to see how many tweets we actually have\n",
    "\n",
    "print(\"There are %d tweets stored in a list as the all_tweets variable.\" % len(all_tweets))\n",
    "print(\"The most recent tweet in our collection was sent %s and the oldest tweet was sent %s.\" % (\n",
    "    all_tweets[0].created_at, \n",
    "    all_tweets[-1].created_at)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Tue Apr 02 13:05:51 +0000 2019\", \"favorite_count\": 820, \"hashtags\": [], \"id\": 1113065005405102080, \"id_str\": \"1113065005405102080\", \"lang\": \"en\", \"quoted_status\": {\"created_at\": \"Tue Apr 02 13:01:12 +0000 2019\", \"favorite_count\": 1144, \"hashtags\": [], \"id\": 1113063833818415104, \"id_str\": \"1113063833818415104\", \"lang\": \"en\", \"retweet_count\": 347, \"source\": \"<a href=\\\"https://about.twitter.com/products/tweetdeck\\\" rel=\\\"nofollow\\\">TweetDeck</a>\", \"text\": \"Sources: the Patriots and DE Michael Bennett have agreed to a reworked two-year deal with a base value of $16.75M,\\u2026 https://t.co/XakOELAwKc\", \"truncated\": true, \"urls\": [{\"expanded_url\": \"https://twitter.com/i/web/status/1113063833818415104\", \"url\": \"https://t.co/XakOELAwKc\"}], \"user\": {\"created_at\": \"Tue Jul 21 20:57:56 +0000 2009\", \"description\": \"NFL Insider for ESPN. Co-host of the Fantasy Focus Football podcast. Graduate of Belmont Hill and Wesleyan.\", \"favourites_count\": 9311, \"followers_count\": 370045, \"friends_count\": 1111, \"geo_enabled\": true, \"id\": 58919137, \"id_str\": \"58919137\", \"lang\": \"en\", \"listed_count\": 6194, \"location\": \"Boston, MA\", \"name\": \"Field Yates\", \"profile_background_color\": \"C0DEED\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_tile\": true, \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/58919137/1540569058\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1047090292883644417/mcBeesbb_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1047090292883644417/mcBeesbb_normal.jpg\", \"profile_link_color\": \"0084B4\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"FieldYates\", \"statuses_count\": 42690, \"url\": \"https://t.co/6GT8n9YwUa\", \"verified\": true}, \"user_mentions\": []}, \"quoted_status_id\": 1113063833818415104, \"quoted_status_id_str\": \"1113063833818415104\", \"retweet_count\": 120, \"source\": \"<a href=\\\"http://twitter.com/download/iphone\\\" rel=\\\"nofollow\\\">Twitter for iPhone</a>\", \"text\": \"A rarity for Patriots to add new money and guaranteed money to existing deal. https://t.co/dzI57vnG66\", \"urls\": [{\"expanded_url\": \"https://twitter.com/fieldyates/status/1113063833818415104\", \"url\": \"https://t.co/dzI57vnG66\"}], \"user\": {\"created_at\": \"Fri Jun 26 22:55:28 +0000 2009\", \"description\": \"Father, Husband, Son, Brother, University of Michigan graduate, masters degree from Medill, NFL Insider for ESPN. https://t.co/oz43ix5jZU\", \"favourites_count\": 405, \"followers_count\": 7337863, \"friends_count\": 2925, \"geo_enabled\": true, \"id\": 51263592, \"id_str\": \"51263592\", \"lang\": \"en\", \"listed_count\": 48739, \"location\": \"New York\", \"name\": \"Adam Schefter\", \"profile_background_color\": \"2573B8\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme4/bg.gif\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme4/bg.gif\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/51263592/1466784770\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/793924061843914752/ycm8ibEE_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/793924061843914752/ycm8ibEE_normal.jpg\", \"profile_link_color\": \"3B94D9\", \"profile_sidebar_border_color\": \"FFFFFF\", \"profile_sidebar_fill_color\": \"95E8EC\", \"profile_text_color\": \"16101F\", \"profile_use_background_image\": true, \"screen_name\": \"AdamSchefter\", \"statuses_count\": 44235, \"url\": \"https://t.co/goIDs6XAeU\", \"verified\": true}, \"user_mentions\": []}\n"
     ]
    }
   ],
   "source": [
    "# take a look at an individual observation\n",
    "\n",
    "print(all_tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How the data appear:\n",
      "The created_at attribute: Tue Apr 02 11:35:48 +0000 2019\n",
      "The hashtags attribute: []\n",
      "The urls attribute: [URL(URL=https://t.co/yH6nVvhfy5, ExpandedURL=https://twitter.com/i/web/status/1113042341038886913)]\n",
      "The source attribute: <a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>\n"
     ]
    }
   ],
   "source": [
    "# features I'm looking closer at\n",
    "\n",
    "print(\"How the data appear:\")\n",
    "print(\"The created_at attribute:\", all_tweets[1].created_at)\n",
    "print(\"The hashtags attribute:\", all_tweets[1].hashtags)\n",
    "print(\"The urls attribute:\", all_tweets[1].urls)\n",
    "print(\"The source attribute:\", all_tweets[1].source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to convert from string to datetime\n",
    "\n",
    "def string_to_datetime(date_str):\n",
    "    \"\"\"\n",
    "    Turns a string including date and time like this - Sun Jul 01 21:06:07 +0000 2018 - to a Python datetime object\n",
    "    like this - datetime.datetime(2018, 7, 1, 21, 6, 7, tzinfo=datetime.timezone.utc)\n",
    "    \"\"\"\n",
    "    return datetime.strptime(date_str, '%a %b %d %H:%M:%S %z %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to clean up urls and sources\n",
    "# which may be useful if I need to expand beyond schefter\n",
    "\n",
    "'''\n",
    "clean_urls turns data with any number of expanded urls like this - \n",
    "    [URL(URL=https://t.co/sYCFHKxzBf, ExpandedURL=https://youtu.be/34bFgA3H3hQ)]- to a list like this - \n",
    "    [\"https://youtu.be/34bFgA3H3hQ\"]\n",
    "    \n",
    "clean_source turns data including the source and some html like this - \n",
    "    <a href=\"https://www.sprinklr.com\" rel=\"nofollow\">Sprinklr</a> - to a list like this -\n",
    "    ['Sprinklr']\n",
    "    \n",
    "clean_hashtags turns data with any number of hashtags like this - [Hashtag(Text='STEMonStation')] - to a list like this -\n",
    "    ['STEMonStation']\n",
    "'''\n",
    "\n",
    "\n",
    "def clean_urls(urls):\n",
    "    cleaned = []\n",
    "    if len(urls) >= 1:\n",
    "        for i in range(len(urls)):\n",
    "            cleaned.append(urls[i].expanded_url)\n",
    "    return(cleaned)\n",
    "        \n",
    "\n",
    "def clean_source(source):\n",
    "    raw = lxml.html.document_fromstring(source)\n",
    "    return raw.cssselect('body')[0].text_content()\n",
    "\n",
    "def clean_hashtags(hashtags):\n",
    "    cleaned = []\n",
    "    if len(hashtags) >= 1:\n",
    "        for i in range(len(hashtags)):\n",
    "            cleaned.append(hashtags[i].text)        \n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(tweets, filename):\n",
    "    # the headers are the fields that we identified to keep\n",
    "    headers = ['id', 'full_text', 'hashtags', 'urls', 'created_at', 'favorite_count', 'retweet_count', 'source']\n",
    "    \n",
    "    # here we create the file and write the header row with the headers list\n",
    "    # note that the 'filename' argument will be the name of the csv file\n",
    "    with open(filename + '.csv', 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow(headers)\n",
    "        \n",
    "        # in this loop, we write a new row for each tweet object, with the data taken from the tweet object in \n",
    "        # the order we listed the headers\n",
    "        # note where we call the helper functions from step 4 on hashtags, urls, and source\n",
    "        for item in tweets:\n",
    "            writer.writerow([item.id, \n",
    "                             item.full_text, \n",
    "                             clean_hashtags(item.hashtags), \n",
    "                             clean_urls(item.urls), \n",
    "                             item.created_at, \n",
    "                             item.favorite_count, \n",
    "                             item.retweet_count, \n",
    "                             clean_source(item.source)])\n",
    "    csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we call the function, passing in the all_tweets list\n",
    "# here the filename will be the screen_name variable defined in step 2 with \"_tweets\" after it (e.g. NASA_tweets.csv),\n",
    "# but you can change it to whatever you want\n",
    "write_to_csv(all_tweets, screen_name + '_tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the second attempt to retrieve data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears there may be a ~3200 tweet limit for scraping a particular user timeline. \n",
    "\n",
    "The first attempt I used at collected Schefter's tweets utilized an R script that produced another dataset consisting of another ~3200 rows from May 21, 2018 to February 17, 2019. There are thus overlapping rows between the two datasets that could be merged to create \n",
    "\n",
    "This first dataset can be seen here: https://github.com/lelarson/Springboard/blob/master/schefter_tweets_2018.csv\n",
    "\n",
    "It appears possible to stream Schefter's tweets into a file using Tweepy: https://tweepy.readthedocs.io/en/v3.5.0/ \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
