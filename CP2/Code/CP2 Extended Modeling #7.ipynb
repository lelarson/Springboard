{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Springboard Data Science Career Track\n",
    "\n",
    "## Capstone Project #2: Learning Neural Networks through Text Generation\n",
    "\n",
    "## Extended Model #7: Changing Number of Memory Units Within Word-Level Model\n",
    "\n",
    "##### By Logan Larson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from numpy import array\n",
    "import string\n",
    "import re\n",
    "from random import randint\n",
    "from pickle import load, dump\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical, np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Embedding\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To Sherlock Holmes she is always THE woman. I have seldom heard\n",
      "him mention her under any other name. \n"
     ]
    }
   ],
   "source": [
    "# load text and convert to lowercase\n",
    "filename = \"AdventuresOfSherlockHolmes.txt\"\n",
    "raw_text = open(filename).read()\n",
    "print(raw_text[:102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'sherlock', 'holmes', 'she', 'is', 'always', 'the', 'woman', 'i', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name']\n"
     ]
    }
   ],
   "source": [
    "# convert to lowercase\n",
    "raw_text = raw_text.lower()\n",
    "# replace dashes\n",
    "raw_text = raw_text.replace('--', '')\n",
    "# split words by white space\n",
    "tokens = raw_text.split()\n",
    "# remove punctuation from each word\n",
    "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "tokens = [re_punc.sub('', w) for w in tokens]\n",
    "# remove any non-alphabetic tokens\n",
    "tokens = [word for word in tokens if word.isalpha()]\n",
    "print(tokens[:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104202"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  104194\n"
     ]
    }
   ],
   "source": [
    "seq_length = 8\n",
    "words = sorted(list(set(tokens)))\n",
    "token_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "dataX = []\n",
    "dataY = []\n",
    "n_tokens = len(tokens)\n",
    "for i in range(0, n_tokens - seq_length, 1):\n",
    "    seq_in = tokens[i:i + seq_length]\n",
    "    seq_out = tokens[i + seq_length]\n",
    "    dataX.append([token_to_int[token] for token in seq_in])\n",
    "    dataY.append(token_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 1\n"
     ]
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# normalize\n",
    "X = X / float(len(words))\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "\n",
    "print(X.shape[1], X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/20\n",
      "104194/104194 [==============================] - 229s 2ms/step - loss: 6.5961\n",
      "\n",
      "Epoch 00001: loss improved from inf to 6.59608, saving model to weights-improvement-01-6.5961.hdf5\n",
      "Epoch 2/20\n",
      "104194/104194 [==============================] - 224s 2ms/step - loss: 6.4569\n",
      "\n",
      "Epoch 00002: loss improved from 6.59608 to 6.45695, saving model to weights-improvement-02-6.4569.hdf5\n",
      "Epoch 3/20\n",
      "104194/104194 [==============================] - 223s 2ms/step - loss: 6.4467\n",
      "\n",
      "Epoch 00003: loss improved from 6.45695 to 6.44669, saving model to weights-improvement-03-6.4467.hdf5\n",
      "Epoch 4/20\n",
      "104194/104194 [==============================] - 222s 2ms/step - loss: 6.4420\n",
      "\n",
      "Epoch 00004: loss improved from 6.44669 to 6.44200, saving model to weights-improvement-04-6.4420.hdf5\n",
      "Epoch 5/20\n",
      "104194/104194 [==============================] - 221s 2ms/step - loss: 6.4292\n",
      "\n",
      "Epoch 00005: loss improved from 6.44200 to 6.42925, saving model to weights-improvement-05-6.4292.hdf5\n",
      "Epoch 6/20\n",
      "104194/104194 [==============================] - 220s 2ms/step - loss: 6.4075\n",
      "\n",
      "Epoch 00006: loss improved from 6.42925 to 6.40751, saving model to weights-improvement-06-6.4075.hdf5\n",
      "Epoch 7/20\n",
      "104194/104194 [==============================] - 218s 2ms/step - loss: 6.3827\n",
      "\n",
      "Epoch 00007: loss improved from 6.40751 to 6.38272, saving model to weights-improvement-07-6.3827.hdf5\n",
      "Epoch 8/20\n",
      "104194/104194 [==============================] - 218s 2ms/step - loss: 6.3494\n",
      "\n",
      "Epoch 00008: loss improved from 6.38272 to 6.34942, saving model to weights-improvement-08-6.3494.hdf5\n",
      "Epoch 9/20\n",
      "104194/104194 [==============================] - 218s 2ms/step - loss: 6.3083\n",
      "\n",
      "Epoch 00009: loss improved from 6.34942 to 6.30826, saving model to weights-improvement-09-6.3083.hdf5\n",
      "Epoch 10/20\n",
      "104194/104194 [==============================] - 218s 2ms/step - loss: 6.2599\n",
      "\n",
      "Epoch 00010: loss improved from 6.30826 to 6.25987, saving model to weights-improvement-10-6.2599.hdf5\n",
      "Epoch 11/20\n",
      "104194/104194 [==============================] - 218s 2ms/step - loss: 6.1935\n",
      "\n",
      "Epoch 00011: loss improved from 6.25987 to 6.19348, saving model to weights-improvement-11-6.1935.hdf5\n",
      "Epoch 12/20\n",
      "104194/104194 [==============================] - 218s 2ms/step - loss: 6.1136\n",
      "\n",
      "Epoch 00012: loss improved from 6.19348 to 6.11358, saving model to weights-improvement-12-6.1136.hdf5\n",
      "Epoch 13/20\n",
      "104194/104194 [==============================] - 227s 2ms/step - loss: 6.0144\n",
      "\n",
      "Epoch 00013: loss improved from 6.11358 to 6.01442, saving model to weights-improvement-13-6.0144.hdf5\n",
      "Epoch 14/20\n",
      "104194/104194 [==============================] - 230s 2ms/step - loss: 5.8986\n",
      "\n",
      "Epoch 00014: loss improved from 6.01442 to 5.89864, saving model to weights-improvement-14-5.8986.hdf5\n",
      "Epoch 15/20\n",
      "104194/104194 [==============================] - 237s 2ms/step - loss: 5.7652\n",
      "\n",
      "Epoch 00015: loss improved from 5.89864 to 5.76519, saving model to weights-improvement-15-5.7652.hdf5\n",
      "Epoch 16/20\n",
      "104194/104194 [==============================] - 241s 2ms/step - loss: 5.6153\n",
      "\n",
      "Epoch 00016: loss improved from 5.76519 to 5.61529, saving model to weights-improvement-16-5.6153.hdf5\n",
      "Epoch 17/20\n",
      "104194/104194 [==============================] - 237s 2ms/step - loss: 5.4549\n",
      "\n",
      "Epoch 00017: loss improved from 5.61529 to 5.45488, saving model to weights-improvement-17-5.4549.hdf5\n",
      "Epoch 18/20\n",
      "104194/104194 [==============================] - 232s 2ms/step - loss: 5.2908\n",
      "\n",
      "Epoch 00018: loss improved from 5.45488 to 5.29084, saving model to weights-improvement-18-5.2908.hdf5\n",
      "Epoch 19/20\n",
      "104194/104194 [==============================] - 239s 2ms/step - loss: 5.1235\n",
      "\n",
      "Epoch 00019: loss improved from 5.29084 to 5.12355, saving model to weights-improvement-19-5.1235.hdf5\n",
      "Epoch 20/20\n",
      "104194/104194 [==============================] - 237s 2ms/step - loss: 4.9600\n",
      "\n",
      "Epoch 00020: loss improved from 5.12355 to 4.96005, saving model to weights-improvement-20-4.9600.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10846aba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-20-4.9600.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" six when i arrived so i went first \"\n",
      "the the the of the the of the the the the the the justified the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "int_to_token = dict((i, c) for i, c in enumerate(words))\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" serious difference it was worth an effort to \"\n",
      "the of the the and the the the lined the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start2 = numpy.random.randint(576, len(dataX)-1)\n",
    "pattern = dataX[start2]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" the door behind me you could not possibly \"\n",
      "the the i and the of the the the the of the the of the the the the the the justified the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start3 = numpy.random.randint(1291, len(dataX)-1)\n",
    "pattern = dataX[start3]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" are doing what you can for him and \"\n",
      "the the i of the plantation and the i the syllables i the the of of the the is the the the of the the of the the the the the the justified the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start4 = numpy.random.randint(291, len(dataX)-1)\n",
    "pattern = dataX[start4]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" when you combine the ideas of whistles at \"\n",
      "the of of the i the the the the the of the the the the the the justified the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start5 = numpy.random.randint(2291, len(dataX)-1)\n",
    "pattern = dataX[start5]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
