{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Springboard Data Science Career Track\n",
    "\n",
    "## Capstone Project #2: Learning Neural Networks through Text Generation\n",
    "\n",
    "## Extended Model #5: Changing Activation Function of Word-Level Model\n",
    "\n",
    "##### By Logan Larson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "//miniconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "from numpy import array\n",
    "import string\n",
    "import re\n",
    "from random import randint\n",
    "from pickle import load, dump\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical, np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Embedding\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To Sherlock Holmes she is always THE woman. I have seldom heard\n",
      "him mention her under any other name. \n"
     ]
    }
   ],
   "source": [
    "# load text and convert to lowercase\n",
    "filename = \"AdventuresOfSherlockHolmes.txt\"\n",
    "raw_text = open(filename).read()\n",
    "print(raw_text[:102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'sherlock', 'holmes', 'she', 'is', 'always', 'the', 'woman', 'i', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name']\n"
     ]
    }
   ],
   "source": [
    "# convert to lowercase\n",
    "raw_text = raw_text.lower()\n",
    "# replace dashes\n",
    "raw_text = raw_text.replace('--', '')\n",
    "# split words by white space\n",
    "tokens = raw_text.split()\n",
    "# remove punctuation from each word\n",
    "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "tokens = [re_punc.sub('', w) for w in tokens]\n",
    "# remove any non-alphabetic tokens\n",
    "tokens = [word for word in tokens if word.isalpha()]\n",
    "print(tokens[:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104202"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  104194\n"
     ]
    }
   ],
   "source": [
    "seq_length = 8\n",
    "words = sorted(list(set(tokens)))\n",
    "token_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "dataX = []\n",
    "dataY = []\n",
    "n_tokens = len(tokens)\n",
    "for i in range(0, n_tokens - seq_length, 1):\n",
    "    seq_in = tokens[i:i + seq_length]\n",
    "    seq_out = tokens[i + seq_length]\n",
    "    dataX.append([token_to_int[token] for token in seq_in])\n",
    "    dataY.append(token_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 1\n"
     ]
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# normalize\n",
    "X = X / float(len(words))\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "\n",
    "print(X.shape[1], X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/20\n",
      "104194/104194 [==============================] - 123s 1ms/step - loss: 6.9435\n",
      "\n",
      "Epoch 00001: loss improved from inf to 6.94350, saving model to weights-improvement-01-6.9435.hdf5\n",
      "Epoch 2/20\n",
      "104194/104194 [==============================] - 100s 960us/step - loss: 6.5930\n",
      "\n",
      "Epoch 00002: loss improved from 6.94350 to 6.59295, saving model to weights-improvement-02-6.5930.hdf5\n",
      "Epoch 3/20\n",
      "104194/104194 [==============================] - 99s 953us/step - loss: 6.5339\n",
      "\n",
      "Epoch 00003: loss improved from 6.59295 to 6.53392, saving model to weights-improvement-03-6.5339.hdf5\n",
      "Epoch 4/20\n",
      "104194/104194 [==============================] - 100s 960us/step - loss: 6.5170\n",
      "\n",
      "Epoch 00004: loss improved from 6.53392 to 6.51696, saving model to weights-improvement-04-6.5170.hdf5\n",
      "Epoch 5/20\n",
      "104194/104194 [==============================] - 104s 1ms/step - loss: 6.5122\n",
      "\n",
      "Epoch 00005: loss improved from 6.51696 to 6.51216, saving model to weights-improvement-05-6.5122.hdf5\n",
      "Epoch 6/20\n",
      "104194/104194 [==============================] - 107s 1ms/step - loss: 6.5070\n",
      "\n",
      "Epoch 00006: loss improved from 6.51216 to 6.50697, saving model to weights-improvement-06-6.5070.hdf5\n",
      "Epoch 7/20\n",
      "104194/104194 [==============================] - 104s 1ms/step - loss: 6.5010\n",
      "\n",
      "Epoch 00007: loss improved from 6.50697 to 6.50100, saving model to weights-improvement-07-6.5010.hdf5\n",
      "Epoch 8/20\n",
      "104194/104194 [==============================] - 104s 997us/step - loss: 6.4911\n",
      "\n",
      "Epoch 00008: loss improved from 6.50100 to 6.49111, saving model to weights-improvement-08-6.4911.hdf5\n",
      "Epoch 9/20\n",
      "104194/104194 [==============================] - 104s 998us/step - loss: 6.4750\n",
      "\n",
      "Epoch 00009: loss improved from 6.49111 to 6.47498, saving model to weights-improvement-09-6.4750.hdf5\n",
      "Epoch 10/20\n",
      "104194/104194 [==============================] - 106s 1ms/step - loss: 6.4599\n",
      "\n",
      "Epoch 00010: loss improved from 6.47498 to 6.45989, saving model to weights-improvement-10-6.4599.hdf5\n",
      "Epoch 11/20\n",
      "104194/104194 [==============================] - 104s 995us/step - loss: 6.4425\n",
      "\n",
      "Epoch 00011: loss improved from 6.45989 to 6.44248, saving model to weights-improvement-11-6.4425.hdf5\n",
      "Epoch 12/20\n",
      "104194/104194 [==============================] - 102s 981us/step - loss: 6.4184\n",
      "\n",
      "Epoch 00012: loss improved from 6.44248 to 6.41840, saving model to weights-improvement-12-6.4184.hdf5\n",
      "Epoch 13/20\n",
      "104194/104194 [==============================] - 106s 1ms/step - loss: 6.3938\n",
      "\n",
      "Epoch 00013: loss improved from 6.41840 to 6.39384, saving model to weights-improvement-13-6.3938.hdf5\n",
      "Epoch 14/20\n",
      "104194/104194 [==============================] - 107s 1ms/step - loss: 6.3662\n",
      "\n",
      "Epoch 00014: loss improved from 6.39384 to 6.36624, saving model to weights-improvement-14-6.3662.hdf5\n",
      "Epoch 15/20\n",
      "104194/104194 [==============================] - 106s 1ms/step - loss: 6.3362\n",
      "\n",
      "Epoch 00015: loss improved from 6.36624 to 6.33615, saving model to weights-improvement-15-6.3362.hdf5\n",
      "Epoch 16/20\n",
      "104194/104194 [==============================] - 104s 999us/step - loss: 6.3074\n",
      "\n",
      "Epoch 00016: loss improved from 6.33615 to 6.30738, saving model to weights-improvement-16-6.3074.hdf5\n",
      "Epoch 17/20\n",
      "104194/104194 [==============================] - 97s 935us/step - loss: 6.2709\n",
      "\n",
      "Epoch 00017: loss improved from 6.30738 to 6.27089, saving model to weights-improvement-17-6.2709.hdf5\n",
      "Epoch 18/20\n",
      "104194/104194 [==============================] - 102s 982us/step - loss: 6.2331\n",
      "\n",
      "Epoch 00018: loss improved from 6.27089 to 6.23307, saving model to weights-improvement-18-6.2331.hdf5\n",
      "Epoch 19/20\n",
      "104194/104194 [==============================] - 100s 955us/step - loss: 6.1937\n",
      "\n",
      "Epoch 00019: loss improved from 6.23307 to 6.19371, saving model to weights-improvement-19-6.1937.hdf5\n",
      "Epoch 20/20\n",
      "104194/104194 [==============================] - 98s 936us/step - loss: 6.1526\n",
      "\n",
      "Epoch 00020: loss improved from 6.19371 to 6.15260, saving model to weights-improvement-20-6.1526.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a3a5518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-20-6.1526.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" i am a very stayathome man and as \"\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "int_to_token = dict((i, c) for i, c in enumerate(words))\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" trivial example of observation and inference therein lies \"\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start2 = numpy.random.randint(576, len(dataX)-1)\n",
    "pattern = dataX[start2]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" series of the funniest stories that i have \"\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start3 = numpy.random.randint(1291, len(dataX)-1)\n",
    "pattern = dataX[start3]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" returned feeling very much easier a horrible doubt \"\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start4 = numpy.random.randint(291, len(dataX)-1)\n",
    "pattern = dataX[start4]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" a likely ruse enough observed bradstreet thoughtfully of \"\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start5 = numpy.random.randint(2291, len(dataX)-1)\n",
    "pattern = dataX[start5]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
