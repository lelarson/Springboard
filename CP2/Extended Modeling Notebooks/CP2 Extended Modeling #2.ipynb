{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Springboard Data Science Career Track\n",
    "\n",
    "## Capstone Project #2: Learning Neural Networks through Text Generation\n",
    "\n",
    "## Extended Model #2: Using Word-Level Inputs\n",
    "\n",
    "##### By Logan Larson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from numpy import array\n",
    "import string\n",
    "import re\n",
    "from random import randint\n",
    "from pickle import load, dump\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical, np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Embedding\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To Sherlock Holmes she is always THE woman. I have seldom heard\n",
      "him mention her under any other name. \n"
     ]
    }
   ],
   "source": [
    "# load text and convert to lowercase\n",
    "filename = \"AdventuresOfSherlockHolmes.txt\"\n",
    "raw_text = open(filename).read()\n",
    "print(raw_text[:102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['to', 'sherlock', 'holmes', 'she', 'is', 'always', 'the', 'woman', 'i', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name']\n"
     ]
    }
   ],
   "source": [
    "# convert to lowercase\n",
    "raw_text = raw_text.lower()\n",
    "# replace dashes\n",
    "raw_text = raw_text.replace('--', '')\n",
    "# split words by white space\n",
    "tokens = raw_text.split()\n",
    "# remove punctuation from each word\n",
    "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "tokens = [re_punc.sub('', w) for w in tokens]\n",
    "# remove any non-alphabetic tokens\n",
    "tokens = [word for word in tokens if word.isalpha()]\n",
    "print(tokens[:19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104202"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  104194\n"
     ]
    }
   ],
   "source": [
    "seq_length = 8\n",
    "words = sorted(list(set(tokens)))\n",
    "token_to_int = dict((c, i) for i, c in enumerate(words))\n",
    "dataX = []\n",
    "dataY = []\n",
    "n_tokens = len(tokens)\n",
    "for i in range(0, n_tokens - seq_length, 1):\n",
    "    seq_in = tokens[i:i + seq_length]\n",
    "    seq_out = tokens[i + seq_length]\n",
    "    dataX.append([token_to_int[token] for token in seq_in])\n",
    "    dataY.append(token_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 1\n"
     ]
    }
   ],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# normalize\n",
    "X = X / float(len(words))\n",
    "\n",
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)\n",
    "\n",
    "print(X.shape[1], X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //miniconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/20\n",
      "104194/104194 [==============================] - 104s 1000us/step - loss: 6.6108\n",
      "\n",
      "Epoch 00001: loss improved from inf to 6.61080, saving model to weights-improvement-01-6.6108.hdf5\n",
      "Epoch 2/20\n",
      "104194/104194 [==============================] - 102s 982us/step - loss: 6.4573\n",
      "\n",
      "Epoch 00002: loss improved from 6.61080 to 6.45732, saving model to weights-improvement-02-6.4573.hdf5\n",
      "Epoch 3/20\n",
      "104194/104194 [==============================] - 103s 986us/step - loss: 6.4473\n",
      "\n",
      "Epoch 00003: loss improved from 6.45732 to 6.44729, saving model to weights-improvement-03-6.4473.hdf5\n",
      "Epoch 4/20\n",
      "104194/104194 [==============================] - 102s 983us/step - loss: 6.4419\n",
      "\n",
      "Epoch 00004: loss improved from 6.44729 to 6.44195, saving model to weights-improvement-04-6.4419.hdf5\n",
      "Epoch 5/20\n",
      "104194/104194 [==============================] - 102s 982us/step - loss: 6.4367\n",
      "\n",
      "Epoch 00005: loss improved from 6.44195 to 6.43669, saving model to weights-improvement-05-6.4367.hdf5\n",
      "Epoch 6/20\n",
      "104194/104194 [==============================] - 99s 952us/step - loss: 6.4276\n",
      "\n",
      "Epoch 00006: loss improved from 6.43669 to 6.42758, saving model to weights-improvement-06-6.4276.hdf5\n",
      "Epoch 7/20\n",
      "104194/104194 [==============================] - 96s 921us/step - loss: 6.4136\n",
      "\n",
      "Epoch 00007: loss improved from 6.42758 to 6.41364, saving model to weights-improvement-07-6.4136.hdf5\n",
      "Epoch 8/20\n",
      "104194/104194 [==============================] - 96s 924us/step - loss: 6.3961\n",
      "\n",
      "Epoch 00008: loss improved from 6.41364 to 6.39614, saving model to weights-improvement-08-6.3961.hdf5\n",
      "Epoch 9/20\n",
      "104194/104194 [==============================] - 96s 923us/step - loss: 6.3741\n",
      "\n",
      "Epoch 00009: loss improved from 6.39614 to 6.37408, saving model to weights-improvement-09-6.3741.hdf5\n",
      "Epoch 10/20\n",
      "104194/104194 [==============================] - 96s 923us/step - loss: 6.3492\n",
      "\n",
      "Epoch 00010: loss improved from 6.37408 to 6.34918, saving model to weights-improvement-10-6.3492.hdf5\n",
      "Epoch 11/20\n",
      "104194/104194 [==============================] - 95s 917us/step - loss: 6.3217\n",
      "\n",
      "Epoch 00011: loss improved from 6.34918 to 6.32166, saving model to weights-improvement-11-6.3217.hdf5\n",
      "Epoch 12/20\n",
      "104194/104194 [==============================] - 94s 899us/step - loss: 6.2917\n",
      "\n",
      "Epoch 00012: loss improved from 6.32166 to 6.29170, saving model to weights-improvement-12-6.2917.hdf5\n",
      "Epoch 13/20\n",
      "104194/104194 [==============================] - 93s 897us/step - loss: 6.2536\n",
      "\n",
      "Epoch 00013: loss improved from 6.29170 to 6.25364, saving model to weights-improvement-13-6.2536.hdf5\n",
      "Epoch 14/20\n",
      "104194/104194 [==============================] - 93s 895us/step - loss: 6.2091\n",
      "\n",
      "Epoch 00014: loss improved from 6.25364 to 6.20912, saving model to weights-improvement-14-6.2091.hdf5\n",
      "Epoch 15/20\n",
      "104194/104194 [==============================] - 93s 896us/step - loss: 6.1577\n",
      "\n",
      "Epoch 00015: loss improved from 6.20912 to 6.15773, saving model to weights-improvement-15-6.1577.hdf5\n",
      "Epoch 16/20\n",
      "104194/104194 [==============================] - 93s 897us/step - loss: 6.0953\n",
      "\n",
      "Epoch 00016: loss improved from 6.15773 to 6.09528, saving model to weights-improvement-16-6.0953.hdf5\n",
      "Epoch 17/20\n",
      "104194/104194 [==============================] - 93s 897us/step - loss: 6.0231\n",
      "\n",
      "Epoch 00017: loss improved from 6.09528 to 6.02311, saving model to weights-improvement-17-6.0231.hdf5\n",
      "Epoch 18/20\n",
      "104194/104194 [==============================] - 92s 880us/step - loss: 5.9369\n",
      "\n",
      "Epoch 00018: loss improved from 6.02311 to 5.93688, saving model to weights-improvement-18-5.9369.hdf5\n",
      "Epoch 19/20\n",
      "104194/104194 [==============================] - 94s 900us/step - loss: 5.8513\n",
      "\n",
      "Epoch 00019: loss improved from 5.93688 to 5.85134, saving model to weights-improvement-19-5.8513.hdf5\n",
      "Epoch 20/20\n",
      "104194/104194 [==============================] - 95s 908us/step - loss: 5.7552\n",
      "\n",
      "Epoch 00020: loss improved from 5.85134 to 5.75521, saving model to weights-improvement-20-5.7552.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x131fa7fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the network weights\n",
    "filename = \"weights-improvement-20-5.7552.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" sure of it i had almost overcome my \"\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "int_to_token = dict((i, c) for i, c in enumerate(words))\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" was a very ordinary black hat of the \"\n",
      "the and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start2 = numpy.random.randint(576, len(dataX)-1)\n",
    "pattern = dataX[start2]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" reptiles neck he drew it from its horrid \"\n",
      "the and the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start3 = numpy.random.randint(1291, len(dataX)-1)\n",
    "pattern = dataX[start3]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" the case is the disposition of the child \"\n",
      "of the the of the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start4 = numpy.random.randint(291, len(dataX)-1)\n",
    "pattern = dataX[start4]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" way as ever came before me now let \"\n",
      "the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the \n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start5 = numpy.random.randint(2291, len(dataX)-1)\n",
    "pattern = dataX[start5]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ' '.join([int_to_token[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(len(words))\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_token[index]\n",
    "    seq_in = [int_to_token[value] for value in pattern]\n",
    "    sys.stdout.write(result + \" \")\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
